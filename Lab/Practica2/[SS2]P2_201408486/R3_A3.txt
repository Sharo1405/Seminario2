#Archivo 3
#Reporte3

import findspark
findspark.init()
from pyspark import SparkContext
from pyspark.sql.session import SparkSession
sc = SparkContext("local", "first app")
spark = SparkSession(sc)
import plotly.graph_objects as go
from pyspark.sql import SQLContext
sqlContext = SQLContext(sc)

#pais, mes, casos, muertes
text_file = sqlContext.read.format('com.databricks.spark.csv').options(header='true', inferschema='true', quote='"', delimiter=',').load("C:\\Users\\sharolin\\Desktop\\entrada\\Covid19.csv")
rddfiltro = text_file.rdd.map(tuple)
rddAERO = rddfiltro.map(lambda word: (word[7],word[3],word[5],word[6]))
rddAERO.take(5)


tablaGT = rddAERO.filter(lambda x: "Guatemala" in x[0] and "August" in x[1])
tablaCasos = tablaGT.map(lambda word: (word[0],word[2]))
tablaMuertes = tablaGT.map(lambda word: (word[0],word[3]))
tablaTotalCasos = tablaCasos.reduceByKey(lambda a,b: a+b)
tablaTotalMuertes = tablaMuertes.reduceByKey(lambda a,b: a+b)
print("Cosos totales -> %s" % tablaTotalCasos.collect())
print("Muertes totales -> %s" % tablaTotalMuertes.collect())

tablaunion = sc.union([tablaTotalCasos,tablaTotalMuertes])
tablaunion.take(2)

newRDD= sc.parallelize(["Casos", "Muertes"])
rddTotales = tablaunion.map(lambda x: (x[1]))
print(newRDD.collect())
print(rddTotales.collect())


fig = go.Figure(data=go.Pie(labels=newRDD.collect(),values=rddTotales.collect()))
fig.update_layout(title_text='Cantidad de Casos y Muertes en Guatemala por Covid 19 en el mes de Agosto',title_font_size=30)
fig.update_traces(hoverinfo='label+percent', textinfo='value',textfont_size=28)
fig.write_html('R3_A3.html', auto_open=True)