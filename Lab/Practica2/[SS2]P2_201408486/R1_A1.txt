##Archivo 1
##Reporte 1
import findspark
findspark.init()
from pyspark import SparkContext
from pyspark.sql.session import SparkSession
sc = SparkContext("local", "first app")
spark = SparkSession(sc)
import plotly.graph_objects as go
from pyspark.sql import SQLContext
sqlContext = SQLContext(sc)

text_file = sqlContext.read.format('com.databricks.spark.csv').options(header='true', inferschema='true', quote='"', delimiter=',').load("C:\\Users\\sharolin\\Desktop\\entrada\\GuatemalaExportsTo.csv")
rddfiltro = text_file.rdd.map(tuple)
rddPAIS = rddfiltro.map(lambda word: (word[4],word[1]))
rddPAIS.take(5)


rddCONTEO=rddPAIS.reduceByKey(lambda a,b: a+b)
print("Conteo total -> %s" % rddCONTEO.collect())


rddORDEN = sc.parallelize(rddCONTEO.sortBy(lambda a: a[1],False).take(5))
print("Pais con mayor valor de exportaciones -> %s" % rddORDEN.collect())


rddNombres = rddORDEN.map(lambda x: (x[0]))
rddTotales = rddORDEN.map(lambda x: (x[1]))
print(rddNombres.collect())
print(rddTotales.collect())


fig = go.Figure(data=go.Bar(x=rddNombres.collect(),y=rddTotales.collect()))
fig.update_layout(title_text='Pais con mayor valor de exportaciones.',title_font_size=30, yaxis=dict(title='Valor exportacion',title_font_size=25), xaxis=dict(title='Pais',title_font_size=25))
fig.update_traces(overwrite=True, marker={"opacity": 0.5})
fig.write_html('R1_A1.html', auto_open=True)